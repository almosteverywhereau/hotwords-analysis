# 热词统计与分析系统 - 系统设计文档

## 1. 项目概述

### 1.1 背景与目标
本项目实现了一个基于滑动窗口的热词统计与分析系统，用于实时处理文本数据流，维护时间窗口内的词频统计，并提供高效的Top-K查询功能。该系统适用于舆情监测、趋势分析、内容推荐等应用场景。

### 1.2 核心功能
- **实时数据流处理**：支持持续接收带时间戳的文本数据
- **中文分词**：集成cppjieba分词库，支持高质量中文分词
- **滑动窗口管理**：基于时间的滑动窗口，可配置窗口大小
- **Top-K热词查询**：快速返回窗口内词频最高的K个词
- **停用词过滤**：自动过滤常见停用词，提高统计质量
- **敏感词过滤**：支持敏感词屏蔽功能
- **趋势分析**：计算词频增长率，识别热门趋势

### 1.3 技术特点
- 使用C++11实现，性能优秀
- 模块化设计，易于扩展
- 支持UTF-8编码的中文文本
- 提供Makefile编译脚本，方便使用

## 2. 系统架构

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────┐
│                  热词统计系统                        │
├─────────────────────────────────────────────────────┤
│                                                     │
│  ┌──────────────┐       ┌──────────────┐          │
│  │  数据采集层  │  -->  │  预处理层    │          │
│  │ (Input File) │       │ (Jieba分词)  │          │
│  └──────────────┘       └──────────────┘          │
│         │                       │                  │
│         v                       v                  │
│  ┌─────────────────────────────────┐              │
│  │        统计核心模块              │              │
│  │  ┌─────────────────────────┐   │              │
│  │  │   实时计数器(HashMap)   │   │              │
│  │  └─────────────────────────┘   │              │
│  │  ┌─────────────────────────┐   │              │
│  │  │   窗口管理器(Queue)     │   │              │
│  │  └─────────────────────────┘   │              │
│  │  ┌─────────────────────────┐   │              │
│  │  │   Top-K维护(Sort)       │   │              │
│  │  └─────────────────────────┘   │              │
│  └─────────────────────────────────┘              │
│         │                                          │
│         v                                          │
│  ┌──────────────┐       ┌──────────────┐          │
│  │  查询服务层  │       │  持久化层    │          │
│  │ (Top-K Query)│       │(Output File) │          │
│  └──────────────┘       └──────────────┘          │
│                                                     │
└─────────────────────────────────────────────────────┘
```

### 2.2 数据流图

```
输入数据流(带时间戳) 
    │
    v
时间戳解析 & 内容提取
    │
    v
中文分词(Jieba)
    │
    v
停用词 & 敏感词过滤
    │
    v
滑动窗口更新
    │
    ├─> 添加新词到计数器
    └─> 移除过期消息
    │
    v
窗口快照保存(用于趋势分析)
    │
    v
Top-K查询 & 结果输出
```

## 3. 核心数据结构设计

### 3.1 实时计数器（HashMap）

**数据结构**：`std::unordered_map<std::string, int>`

**功能**：维护窗口内每个词的出现次数

**时间复杂度分析**：
- 插入/更新：O(1) 平均时间
- 查询：O(1) 平均时间
- 删除：O(1) 平均时间

**空间复杂度**：O(V)，V为窗口内唯一词数

**优势**：
- 哈希表提供常数时间的插入、查询、删除操作
- C++ STL实现经过优化，性能稳定

### 3.2 时间窗口管理器（Queue + HashMap）

**数据结构**：
```cpp
std::queue<std::pair<Timestamp, std::vector<std::string>>> messageQueue
```

**功能**：
- 维护窗口内所有消息的时间戳和分词结果
- 支持滑动窗口的过期数据淘汰

**滑动策略**：
- 窗口类型：基于时间的固定大小窗口
- 窗口大小：可配置（默认600秒，即10分钟）
- 淘汰策略：每次添加新消息时，检查队首消息是否过期，若过期则移除并更新词频

**时间复杂度分析**：
- 添加消息：O(W) 平均，W为分词后的词数
- 过期淘汰：O(M × W)，M为过期消息数，通常M较小
- 总体复杂度：O(W)，因为每个消息只入队出队一次

**空间复杂度**：O(N × W)，N为窗口内消息数

**设计取舍**：
- 使用队列保存完整消息，可精确追踪每个词的时间信息
- 相比时间分桶方案，内存开销稍大，但实现简单且精确

### 3.3 Top-K维护结构（Sorting）

**数据结构**：`std::vector<WordFreq>` + 排序

**实现方式**：
1. 从HashMap中提取所有词频对
2. 使用`std::sort`进行排序
3. 返回前K个元素

**时间复杂度分析**：
- Top-K查询：O(V log V)，V为唯一词数
- 排序使用快速排序/归并排序

**空间复杂度**：O(V) 临时空间

**优化方案**（可选）：
- 如果查询频繁，可维护平衡树（如`std::set`）：O(log V)查询
- 如果K很小，可使用小顶堆：O(V + K log K)
- 当前实现简单直接，适合中等规模数据

**设计取舍**：
- 选择排序方案因为：
  1. 实现简单，代码清晰
  2. STL排序高度优化
  3. 查询不是高频操作，O(V log V)可接受
  4. 支持灵活的排序规则（频率+字典序）

### 3.4 数据结构关系图

```
┌────────────────────────────────────┐
│       SlidingWindow Class          │
├────────────────────────────────────┤
│                                    │
│  wordCount: unordered_map          │  <- 实时计数器
│    Key: string (词)                │
│    Value: int (频率)               │
│                                    │
│  messageQueue: queue               │  <- 时间窗口
│    Element: <Timestamp, Words[]>   │
│                                    │
│  stopWords: set                    │  <- 停用词
│  sensitiveWords: set               │  <- 敏感词
│                                    │
│  history: vector<Snapshot>         │  <- 历史快照
│                                    │
├────────────────────────────────────┤
│  Methods:                          │
│  + addMessage(ts, words)           │
│  + removeExpiredMessages(ts)       │
│  + getTopK(k) -> WordFreq[]        │
│  + getTrend(word) -> double        │
└────────────────────────────────────┘
```

## 4. 算法详细说明

### 4.1 滑动窗口淘汰算法

**伪代码**：
```
function removeExpiredMessages(currentTime):
    windowStart = currentTime.toSeconds() - windowSize
    
    while messageQueue is not empty:
        front = messageQueue.front()
        if front.timestamp < windowStart:
            // 消息过期，移除
            for each word in front.words:
                wordCount[word]--
                if wordCount[word] == 0:
                    delete wordCount[word]
            messageQueue.pop()
        else:
            break  // 队首未过期，后续消息也不会过期
```

**正确性保证**：
- 队列按时间顺序入队，保证先入先出
- 每次只检查队首，利用时间单调性提高效率

**时间复杂度**：
- 最坏情况：O(N × W)，N为队列长度
- 平均情况：O(M × W)，M为过期消息数，通常M << N
- 均摊复杂度：O(1)，因为每个消息只处理一次

### 4.2 Top-K查询算法

**伪代码**：
```
function getTopK(k):
    result = []
    for (word, count) in wordCount:
        result.append(WordFreq(word, count))
    
    sort(result, by=count DESC, then by word ASC)
    
    return result[0:k]
```

**时间复杂度**：O(V log V)，V为唯一词数

**优化策略**：
- 使用STL高效排序算法
- 支持自定义比较器（频率优先，字典序次之）

### 4.3 趋势分析算法

**计算公式**：
```
增长率 = (当前窗口词频 - 前一窗口词频) / 前一窗口词频 × 100%
```

**实现方式**：
- 定期保存窗口快照（每次查询时）
- 比较最近两个快照的词频差异

**应用场景**：
- 识别快速上升的热词
- 检测词频趋势变化

## 5. 性能分析

### 5.1 时间复杂度总结

| 操作 | 时间复杂度 | 说明 |
|------|-----------|------|
| 添加消息 | O(W) | W为分词后词数 |
| 窗口淘汰 | O(1) 均摊 | 每个消息只处理一次 |
| Top-K查询 | O(V log V) | V为唯一词数 |
| 词频更新 | O(1) | 哈希表操作 |
| 趋势计算 | O(1) | 直接查表 |

### 5.2 空间复杂度总结

| 数据结构 | 空间复杂度 | 说明 |
|---------|-----------|------|
| wordCount | O(V) | V为唯一词数 |
| messageQueue | O(N × W) | N为窗口内消息数 |
| stopWords | O(S) | S为停用词数量（约1000） |
| history | O(H × V) | H为快照数量 |
| **总计** | **O(N × W + V)** | 主要取决于窗口大小 |

### 5.3 性能估算

**假设条件**：
- 窗口大小：10分钟（600秒）
- 消息到达速率：100条/秒
- 平均每条消息：10个词
- 唯一词数：约5000

**内存估算**：
- messageQueue: 60,000 × 10 × 8字节 ≈ 4.8 MB
- wordCount: 5,000 × (20 + 4)字节 ≈ 120 KB
- 总内存：约 5-10 MB

**查询延迟**：
- Top-K查询：5000 × log(5000) ≈ 42,000次比较
- 现代CPU：约 0.1-1 ms

## 6. 功能实现说明

### 6.1 已实现的核心功能

✅ **实时数据流处理**
- 支持从文件读取带时间戳的数据流
- 格式：`[H:MM:SS] 文本内容`

✅ **中文分词**
- 使用cppjieba高质量分词库
- 支持HMM新词发现

✅ **滑动窗口统计**
- 基于时间的固定窗口
- 自动淘汰过期数据
- 精确维护词频统计

✅ **Top-K查询**
- 支持任意K值查询
- 按频率降序、字典序升序排列
- 实时响应查询请求

✅ **停用词过滤**
- 加载停用词表（1279个）
- 自动过滤无意义词

✅ **敏感词过滤**
- 支持敏感词配置
- 自动屏蔽敏感词统计

✅ **趋势分析**
- 计算词频增长率
- 标记上升/下降趋势

### 6.2 高级功能

✅ **历史快照**
- 保存每次查询时的窗口状态
- 支持趋势分析

✅ **统计信息**
- 实时显示窗口内消息数
- 唯一词数、总词数统计

### 6.3 配置选项

- **窗口大小**：命令行参数可配置（秒）
- **输入文件**：支持自定义输入文件
- **输出文件**：支持自定义输出文件
- **分词模式**：使用HMM模式（高精度）

## 7. 使用说明

### 7.1 编译

```bash
make          # 编译主程序
make demo     # 编译演示程序
make clean    # 清理编译文件
```

### 7.2 运行

```bash
# 基本用法
./hotwords input.txt output.txt [窗口大小(秒)]

# 示例
./hotwords input1.txt result.txt 600    # 10分钟窗口
./hotwords input1.txt result.txt 300    # 5分钟窗口
./hotwords input1.txt result.txt 1200   # 20分钟窗口

# 使用Makefile快速运行
make run      # 使用默认配置运行
make test     # 测试不同窗口大小
```

### 7.3 输入格式

```
[H:MM:SS] 文本内容
[H:MM:SS] 文本内容
[ACTION] QUERY K=数字
...
```

### 7.4 输出格式

```
[时间: H:MM:SS] Query #N - Top-K 热词:
  1. 词1 (出现 X 次) ↑增长率%
  2. 词2 (出现 Y 次)
  ...
```

## 8. 测试与验证

### 8.1 功能测试

✅ **分词正确性**
- 测试中文分词效果
- 验证停用词过滤

✅ **窗口管理**
- 验证消息正确入队出队
- 测试过期数据淘汰

✅ **Top-K正确性**
- 验证查询结果准确性
- 测试边界情况（K > 唯一词数）

### 8.2 性能测试

测试环境：
- 系统：macOS
- 编译器：g++ -O2
- 测试数据：12,870行真实弹幕数据

测试结果：
- 处理速度：约 5000-6000 条/秒
- 内存占用：约 10-20 MB
- Top-K查询延迟：< 1 ms
- 窗口更新：实时响应

### 8.3 压力测试

✅ **大规模数据**
- 成功处理12,870条消息
- 窗口内维护约2000-3000条消息
- 唯一词数3000-4000

✅ **频繁查询**
- 16次Top-K查询
- 查询响应稳定

## 9. 设计亮点

### 9.1 数据结构选择
- **哈希表**：O(1)词频更新，性能优秀
- **队列**：FIFO特性完美匹配滑动窗口
- **组合使用**：充分发挥各自优势

### 9.2 算法优化
- **惰性淘汰**：只在必要时检查过期数据
- **均摊分析**：每个消息只处理一次
- **STL优化**：使用高效的标准库实现

### 9.3 工程实践
- **模块化设计**：SlidingWindow类封装核心逻辑
- **异常处理**：文件读写、参数验证
- **日志输出**：详细的运行信息

### 9.4 扩展性
- **可配置窗口**：支持不同时间粒度
- **可插拔过滤**：停用词、敏感词独立配置
- **趋势分析**：为高级功能预留接口

## 10. 未来改进方向

### 10.1 性能优化
- [ ] 使用小顶堆优化Top-K查询（当K << V时）
- [ ] 多线程处理：分词、统计、查询并行化
- [ ] 内存池管理：减少频繁内存分配

### 10.2 功能增强
- [ ] 支持多种窗口类型（滑动、翻滚、会话）
- [ ] 实时可视化界面（Web/GUI）
- [ ] 词云生成
- [ ] 高级趋势预测（时间序列分析）

### 10.3 数据源扩展
- [ ] 支持实时数据流（TCP/HTTP）
- [ ] 支持多文件并发处理
- [ ] 支持分布式部署

## 11. 参考资料

- cppjieba: https://github.com/yanyiwu/cppjieba
- 滑动窗口算法：经典数据结构教材
- Top-K算法：算法导论
- C++ STL性能分析：Effective STL

## 12. 附录

### 12.1 文件清单

```
Project/
├── hotwords.cpp              # 主程序源码
├── demo.cpp                  # 分词演示程序
├── Makefile                  # 编译脚本
├── 系统设计文档.md           # 本文档
├── 性能测试报告.md           # 性能测试
├── Readme.md                 # 项目说明
├── input1.txt                # 测试输入（12870行）
├── test_input.txt            # 简单测试输入
├── hotwords_output.txt       # 输出结果
├── cppjieba/                 # 分词库头文件
└── dict/                     # 词典文件
    ├── jieba.dict.utf8       # 主词典
    ├── hmm_model.utf8        # HMM模型
    ├── user.dict.utf8        # 用户词典
    ├── idf.utf8              # TF-IDF
    ├── stop_words.utf8       # 停用词
    └── sensitive_words.utf8  # 敏感词
```

### 12.2 核心代码统计

- 总代码行数：约 500 行
- 核心逻辑：约 300 行
- 注释行数：约 100 行
- 代码质量：清晰、模块化、注释完善

---

**文档版本**：v1.0  
**创建日期**：2025年12月5日  
**作者**：数据结构大作业  
**项目名称**：热词统计与分析系统
